# Kafka环境搭建
##########################<br/>
\#     JDK 8.0            <br/>
\#     Zookeeper 3.4      <br/>
\#     Kafka 2.12          <br/>
##########################<br/>
<hr>

# Zookeeper安装
## 上传到服务器 然后进行解压缩
## rename zookeeper 配置文件 zookeeper/conf/
### 在解压缩后zookeeper的配置文件需要改为zoo.cfg
<hr>

# zookeeper 环境搭建
## zookeeper下载地址
### zookeeper.apache.org
## 上传到服务器 然后进行解压缩
## rename zookeeper 配置文件 zookeeper/conf/
### 在解压缩后zookeeper的配置文件需要改为zoo.cfg
<hr>

## zookeeper配置文件说明

```
\# The number of milliseconds of each tick

\# zookeeper 心跳时间
tickTime=2000
\# The number of ticks that the initial
\# synchronization phase can take

\#选举新leader初始化的时间
initLimit=10
\# The number of ticks that can pass between
\# sending a request and getting an acknowledgement

syncLimit=5
\# the directory where the snapshot is stored.
\# do not use /tmp for storage, /tmp here is just
\# example sakes.
\# 数据存放目录 需要自行指定
dataDir=/tmp/zookeeper/data
\# the port at which the clients will connect

\# 客户端访问端口
clientPort=2181
\# the maximum number of client connections.
\# increase this if you need to handle more clients
\#maxClientCnxns=60
#
\# Be sure to read the maintenance section of the
\# administrator guide before turning on autopurge.
#
\# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
\# The number of snapshots to retain in dataDir
\#autopurge.snapRetainCount=3
\# Purge task interval in hours
\# Set to "0" to disable auto purge feature
\#autopurge.purgeInterval=1
```
## 启动zookeeper
### zookeeper/bin/zkServer.sh start zookeeper/conf/zoo.cfg
<hr />


# kafka的安装

## kafka下载地址
### https://kafka.apache.org/downloads
### 下载后上传至服务器 然后解压缩
## kafka的配置说明
```
broker.id=0  broker的编号 用来区分集群时 多个broker
listeners=PLAINTEXT://:9092  broker对外提供的服务入口地址
log.dirs=/tmp/kafka-logs  日志存放目录
zookeeper.connect=localhost:2181  kafka连接zookeeper集群的地址 (可以都放在同一台机器上)
zookeeper.connection.timeout.ms=18000 kafka连接zookeeper的超时时间
advertised.listeners=PLAINTEXT://192.168.199.126:9092 配置远程访问 如果不配置禁止远程访问

```
## 配置kafka的远程连接
在kafka/conf/server.properties中修改advertised.listeners 将值改为IP地址

## 常用配置项说明
### zookeeper.connect
#### zookeeper的连接地址 如果是zookeeper集群 则使用逗号隔开
### listeners
#### 监听列表 对外提供服务时绑定的IP和端口 如果有多个 则逗号隔开
#### 如果监听的名称不一致 则需要设置
#### listener.security,protocol.map
#### 绑定的主机为0.0.0.0时 是绑定所有IP
#### 绑定主机IP为空则使用默认
#### 例如 PLAINTEXT://myHost:9092,SSL://:9091 CLIENT://0.0.0.0:9092,REPLICATION://localhost:9093

### broker.id
#### broker的唯一标识 默认-1 用于标注集群中的broker

### log.dirs
#### 日志存放目录 默认使用log.dir

### message.max.bytes
#### 服务器接收单个消息的最大字节数 默认约976KB

## 启动Kafka
### 在kafka/bin目录下 执行
### 注意：如果启动时不带有指定的配置文件 则会采用默认配置文件进行启动
### bin/kafka-server-start.sh config/server.properties

## 测试生产与消费
### 首先创建Topic
#### bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic eeeee --partitions 2 --replication-factor 1
```
指令说明
--zookeeper 指定kafka连接zookeeper的地址
--topic 指定创建的主题名称
--partitions 指定分区个数 (kafka中消息是发布到分区下面的)
--replication-factor 指定副本因子 (partition分区的副本)
-- create 创建主题的动作指令
```

## 查看已创建的topic
### bin/kafka-topics.sh --zookeeper localhost:2181 --list

## 查看topic详情
### bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic etjava

## 启动消费者接收消息
## bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic etjava
```
参数说明
--bootstrap-server 消费者连接kafka的地址
--topic 指定订阅的主题

```
## 启动生产者生产消息
### bin/kafka-console-producer.sh --broker-list localhost:9092 --topic etjava
```
参数说明
--broker-list 生产者连接kafka的地址
--topic 发布消息的主题

```
**在生产者的控制台中输入消息 在消费者端会实时监听到生产者发布的消息**
